{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `nltk` we can download translated sentences between different languages. You can see the example between **English and French** below but feel free to try different combination as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package comtrans to /home/jewelle/nltk_data...\n",
      "[nltk_data]   Package comtrans is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('comtrans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AlignedSent: 'Resumption of the se...' -> 'Reprise de la sessio...'>\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import comtrans\n",
    "print(comtrans.aligned_sents('alignment-en-fr.txt')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comtrans.aligned_sents('alignment-en-fr.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually building a translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jewelle/.keras/datasets/fra.txt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### FRENCH TO ENGLISH\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'fra-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path = os.path.dirname(path_to_zip)+'/fra.txt'\n",
    "#path_to_file = os.path.dirname(path_to_zip)+\"/fra.txt\" \n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "    if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> i m going to vomit . <end>\n",
      "b'<start> j ai envie de vomir . <end>'\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "en_sentence = u\"I’m going to vomit.\"\n",
    "fr_sentence = u\"J’ai envie de vomir.\"\n",
    "\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(fr_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jewelle/data_bootcamp/w9/mini-project-V'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file= '/home/jewelle/data_bootcamp/w9/mini-project-V/combo.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n') #clean accents\n",
    "\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]] #return pairs\n",
    "\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d235659faf58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0men\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "en, fr = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(fr[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "    # creating cleaned input, output pairs\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(lr=0.001)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-971fa13c50c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n\u001b[0;32m----> 4\u001b[0;31m                                  \u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                                  decoder=decoder)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "#checkpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        #Pass the input through the encoder which return encoder output and the encoder hidden state.\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        #decoder returns the predictions and the decoder hidden state.\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        #Teacher forcing - feeding the target as the next input\n",
    "        #Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n",
    "        for t in range(1, targ.shape[1]):\n",
    "          # passing enc_output to the decoder\n",
    "          predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "        loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "        # using teacher forcing\n",
    "        dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                    batch,\n",
    "                                                    batch_loss.numpy()))\n",
    "  # checkpoint the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "        return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
