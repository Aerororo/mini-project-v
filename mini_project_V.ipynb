{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `nltk` we can download translated sentences between different languages. You can see the example between **English and French** below but feel free to try different combination as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package comtrans to /home/jewelle/nltk_data...\n",
      "[nltk_data]   Package comtrans is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('comtrans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AlignedSent: 'Resumption of the se...' -> 'Reprise de la sessio...'>\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import comtrans\n",
    "print(comtrans.aligned_sents('alignment-en-fr.txt')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comtrans.aligned_sents('alignment-en-fr.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually building a translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "from numpy.random import rand, shuffle\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from unicodedata import normalize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from konoha import WordTokenizer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pickle import dump\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10285000692917845906\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17578154472098912852\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16682677706235892000\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/jewelle/data_bootcamp/w9/mini-project-V/'\n",
    "\n",
    "data = read_text(path + 'fra.txt') #dataset from Ballad of Edgardo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "        # open the file\n",
    "        file = open(filename, mode='rt', encoding='utf-8')\n",
    "        \n",
    "        # read all text\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lines(text):\n",
    "      sents = text.strip().split('\\n')\n",
    "      sents = [i.split('\\t') for i in sents]\n",
    "      return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_en = to_lines(data)\n",
    "es_en = array(es_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Go.', 'Ve.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986655 (cueyayotl)'],\n",
       "       ['Go.', 'Vete.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986656 (cueyayotl)'],\n",
       "       ['Go.', 'Vaya.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986657 (cueyayotl)'],\n",
       "       ...,\n",
       "       ['A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.',\n",
       "        'Una huella de carbono es la cantidad de contaminación de dióxido de carbono que producimos como producto de nuestras actividades. Algunas personas intentan reducir su huella de carbono porque están preocupados acerca del cambio climático.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1141316 (Source_VOA) & #1336787 (marcelostockle)'],\n",
       "       ['Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.',\n",
       "        'Como suele haber varias páginas web sobre cualquier tema, normalmente sólo le doy al botón de retroceso cuando entro en una página web que tiene anuncios en ventanas emergentes. Simplemente voy a la siguiente página encontrada por Google y espero encontrar algo menos irritante.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #1329373 (Shishir)'],\n",
       "       ['If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.',\n",
       "        'Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #953962 (CK) & #1218695 (marcelostockle)']],\n",
       "      dtype='<U278')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "es_en[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in es_en[:,0]]\n",
    "es_en[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in es_en[:,1]]\n",
    "\n",
    "# convert text to lowercase\n",
    "for i in range(len(es_en)):\n",
    "    es_en[i,0] = es_en[i,0].lower()\n",
    "    es_en[i,1] = es_en[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['go', 've',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986655 (cueyayotl)'],\n",
       "       ['go', 'vete',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986656 (cueyayotl)'],\n",
       "       ['go', 'vaya',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #4986657 (cueyayotl)'],\n",
       "       ...,\n",
       "       ['a carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities some people try to reduce their carbon footprint because they are concerned about climate change',\n",
       "        'una huella de carbono es la cantidad de contaminación de dióxido de carbono que producimos como producto de nuestras actividades algunas personas intentan reducir su huella de carbono porque están preocupados acerca del cambio climático',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1141316 (Source_VOA) & #1336787 (marcelostockle)'],\n",
       "       ['since there are usually multiple websites on any given topic i usually just click the back button when i arrive on any webpage that has popup advertising i just go to the next page found by google and hope for something less irritating',\n",
       "        'como suele haber varias páginas web sobre cualquier tema normalmente sólo le doy al botón de retroceso cuando entro en una página web que tiene anuncios en ventanas emergentes simplemente voy a la siguiente página encontrada por google y espero encontrar algo menos irritante',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #1329373 (Shishir)'],\n",
       "       ['if you want to sound like a native speaker you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo',\n",
       "        'si quieres sonar como un hablante nativo debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #953962 (CK) & #1218695 (marcelostockle)']],\n",
       "      dtype='<U278')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into sentence pairs\n",
    "\n",
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in  lines]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean line by line\n",
    "def clean_pairs(lines):\n",
    "    cleaned = list()\n",
    "    \n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for pair in lines:\n",
    "        clean_pair = list()\n",
    "    \n",
    "    for line in pair:\n",
    "        # normalize unicode characters\n",
    "        line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "        line = line.decode('UTF-8')\n",
    "        # tokenize on white space\n",
    "        line = line.split()\n",
    "        # convert to lowercase\n",
    "        line = [word.lower() for word in line]\n",
    "        # remove punctuation from each token\n",
    "        line = [word.translate(table) for word in line]\n",
    "        # remove non-printable chars form each token\n",
    "        line = [re_print.sub('', w) for w in line]\n",
    "        # remove tokens with numbers in them\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "        # store as string\n",
    "        clean_pair.append(' '.join(line))\n",
    "    cleaned.append(clean_pair)\n",
    "    return array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a list of clean sentences to file\n",
    "def save_clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "filename = 'fra.txt'\n",
    "doc = read_text(filename)\n",
    "\n",
    "# split into english-other lang sentence pairs\n",
    "pairs = to_pairs(doc)\n",
    "\n",
    "# extensive clean sentences\n",
    "clean_pairs = clean_pairs(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[if someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker in other words you dont really sound like a native speaker] => [si quelquun qui ne connait pas vos antecedents dit que vous parlez comme un locuteur natif cela veut dire quil a probablement remarque quelque chose a propos de votre elocution qui lui a fait prendre conscience que vous netes pas un locuteur natif en dautres termes vous ne parlez pas vraiment comme un locuteur natif]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d366b145baee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# spot check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[%s] => [%s]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclean_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "# spot check\n",
    "for i in range(100):\n",
    "    print('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: fra_en_raw.pkl\n"
     ]
    }
   ],
   "source": [
    "# save clean data to file\n",
    "save_clean_data(clean_pairs, 'fra_en_raw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: combined-data.pkl\n",
      "Saved: fra-en-train.pkl\n",
      "Saved: fra-en-test.pkl\n"
     ]
    }
   ],
   "source": [
    "# load a clean dataset\n",
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    " \n",
    "# load dataset\n",
    "data = load_clean_sentences('fra_en_raw.pkl')\n",
    " \n",
    "# reduce dataset size\n",
    "n = 10000\n",
    "dataset = data[:n, :]\n",
    "# random shuffle\n",
    "shuffle(dataset)\n",
    "# split into train/test\n",
    "train, test = data[:9000], data[9000:]\n",
    "# save\n",
    "save_clean_data(data, 'combined-data.pkl')\n",
    "save_clean_data(train, 'fra-en-train.pkl')\n",
    "save_clean_data(test, 'fra-en-test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ja_tokenization(lines):\n",
    "    ja_tokenizer = WordTokenizer('MeCab')\n",
    "    ja_tokenizer.fit_on_texts(lines)\n",
    "    return ja_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for finding maximum length of sentence\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 33\n",
      "English Max Length: 44\n"
     ]
    }
   ],
   "source": [
    "# english tokenizer\n",
    "eng_tokenizer = tokenization(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French Vocabulary Size: 39\n",
      "French Max Length: 44\n"
     ]
    }
   ],
   "source": [
    "# prepare other language tokenizer\n",
    "fr_tokenizer = tokenization(dataset[:, 1])\n",
    "fr_vocab_size = len(fr_tokenizer.word_index) + 1\n",
    "fr_length = max_length(dataset[:, 0])\n",
    "\n",
    "print('French Vocabulary Size: %d' % fr_vocab_size)\n",
    "print('French Max Length: %d' % (fr_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences to max length\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "        sequence = tokenizer.texts_to_sequences(lines)\n",
    "        # pad sequences with 0 values\n",
    "        sequence = pad_sequences(sequence, maxlen=length, padding='post')\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a8938d921043>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# split data into train and test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2129\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2131\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1812\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[0;32m-> 1814\u001b[0;31m                                                 train_size)\n\u001b[0m\u001b[1;32m   1815\u001b[0m         )\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# split data into train and test set\n",
    "train, test = train_test_split(dataset, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "X_train = encode_sequences(fr_tokenizer, fr_length, train[:, 1])\n",
    "y_train = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test data\n",
    "X_test = encode_sequences(fr_tokenizer, fr_length, test[:, 1])\n",
    "y_test = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compilation\n",
    "model = define_model(fr_vocab_size, eng_vocab_size, fr_length, eng_length, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMS is good optimizer for RNNs\n",
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 9/13 [===================>..........] - ETA: 2:40 - loss: 1.2689ETA: 1:51 - loss: 1.271"
     ]
    }
   ],
   "source": [
    "filename = 'model.mini_project_v'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# train model\n",
    "history = model.fit(X_train, y_train.reshape(y_train.shape[0], y_train.shape[1], 1),\n",
    "                    epochs=10, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.mini_project_v')\n",
    "preds = model.predict_classes(X_test.reshape((X_test.shape[0],X_test.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return array to words\n",
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init predictions\n",
    "preds_text = []\n",
    "\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None): \n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t) \n",
    "\n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whats this</td>\n",
       "      <td>he tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marry me</td>\n",
       "      <td>they be me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is this correct</td>\n",
       "      <td>is was my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>please listen</td>\n",
       "      <td>please sit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he bit his lip</td>\n",
       "      <td>he is the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            actual      predicted\n",
       "0       whats this      he tom   \n",
       "1         marry me   they be me  \n",
       "2  is this correct    is was my  \n",
       "3    please listen  please sit   \n",
       "4   he bit his lip    he is the  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Please set MECAB_CHARSET before running the tests",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-301-b974d5e0659a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aimport'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'helper, tests'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2315\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/jewelle/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-127>\u001b[0m in \u001b[0;36maimport\u001b[0;34m(self, parameter_s, stream)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\u001b[0m in \u001b[0;36maimport\u001b[0;34m(self, parameter_s, stream)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                 \u001b[0mtop_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0;31m# Inject module to user namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/extensions/autoreload.py\u001b[0m in \u001b[0;36maimport_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_module_reloadable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mtop_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mtop_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tests/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# as well as the character encoding used internally by MeCab...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMECAB_CHARSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please set MECAB_CHARSET before running the tests'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# and the mecab 0.996 executable is invoked during the tests...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Please set MECAB_CHARSET before running the tests"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%aimport helper, tests\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "import collections\n",
    "\n",
    "# Load English data\n",
    "en_sentences = read_text(path +'en_small.txt')\n",
    "# Load French data\n",
    "fr_sentences = read_text(path +'fr_small.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en Line 1:  n\n",
      "fr Line 1:  n\n",
      "en Line 2:  e\n",
      "fr Line 2:  e\n"
     ]
    }
   ],
   "source": [
    "for sample_i in range(2):\n",
    "    print('en Line {}:  {}'.format(sample_i + 1, en_sentences[sample_i]))\n",
    "    print('fr Line {}:  {}'.format(sample_i + 1, fr_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7261975 English words.\n",
      "30 unique English words.\n",
      "10 Most common words in the English dataset:\n",
      "\"i\" \"e\" \"s\" \"t\" \"r\" \"a\" \"n\" \"u\" \"l\" \"d\"\n",
      "\n",
      "7885766 French words.\n",
      "39 unique French words.\n",
      "10 Most common words in the French dataset:\n",
      "\"e\" \"s\" \"a\" \"i\" \"t\" \"l\" \"n\" \"r\" \"m\" \"o\"\n"
     ]
    }
   ],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in en_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in fr_sentences for word in sentence.split()])\n",
    "\n",
    "print('{} English words.'.format(len([word for sentence in en_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} French words.'.format(len([word for sentence in fr_sentences for word in sentence.split()])))\n",
    "print('{} unique French words.'.format(len(french_words_counter)))\n",
    "print('10 Most common words in the French dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
      "\n",
      "Sequence 1 in x\n",
      "  Input:  The quick brown fox jumps over the lazy dog .\n",
      "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "Sequence 2 in x\n",
      "  Input:  By Jove , my quick study of lexicography won a prize .\n",
      "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "Sequence 3 in x\n",
      "  Input:  This is a short sentence .\n",
      "  Output: [18, 19, 3, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "\n",
    "    # TODO: Implement\n",
    "    x_tk = Tokenizer(char_level = False)\n",
    "    x_tk.fit_on_texts(x)\n",
    "    return x_tk.texts_to_sequences(x), x_tk\n",
    "\n",
    "# Tokenize Example output\n",
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print()\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-300-cf03f7bd2096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Pad Tokenized output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tests' is not defined"
     ]
    }
   ],
   "source": [
    "def pad(x, length=None):\n",
    "    \"\"\"\n",
    "    Pad x\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    return pad_sequences(x, maxlen = length, padding = 'post')\n",
    "\n",
    "tests.test_pad(pad)\n",
    "\n",
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
